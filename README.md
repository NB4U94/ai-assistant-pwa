<template>

Â  <div class="chat-view">

Â  Â  <div class="assistant-selector-area">

Â  Â  Â  <div class="assistant-selector-row">

Â  Â  Â  Â  <div

Â  Â  Â  Â  Â  :class="['assistant-selector-item', !selectedAssistantId ? 'selected' : '']"

Â  Â  Â  Â  Â  @click="selectAssistant(null)"

Â  Â  Â  Â  Â  title="Select Default Assistant"

Â  Â  Â  Â  Â  tabindex="0"

Â  Â  Â  Â  Â  @keydown.enter.prevent="selectAssistant(null)"

Â  Â  Â  Â  Â  @keydown.space.prevent="selectAssistant(null)"

Â  Â  Â  Â  >

Â  Â  Â  Â  Â  <div class="assistant-selector-avatar">

Â  Â  Â  Â  Â  Â  <div class="assistant-placeholder default-placeholder">?</div>

Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  Â  <span class="assistant-selector-name">Default AI</span>

Â  Â  Â  Â  </div>

Â  Â  Â  Â  <div

Â  Â  Â  Â  Â  v-for="assistant in availableAssistants"

Â  Â  Â  Â  Â  :key="assistant.id"

Â  Â  Â  Â  Â  :class="[

Â  Â  Â  Â  Â  Â  'assistant-selector-item',

Â  Â  Â  Â  Â  Â  selectedAssistantId === assistant.id ? 'selected' : '',

Â  Â  Â  Â  Â  ]"

Â  Â  Â  Â  Â  @click="selectAssistant(assistant.id)"

Â  Â  Â  Â  Â  :title="`Select Assistant: ${assistant.name}`"

Â  Â  Â  Â  Â  tabindex="0"

Â  Â  Â  Â  Â  @keydown.enter.prevent="selectAssistant(assistant.id)"

Â  Â  Â  Â  Â  @keydown.space.prevent="selectAssistant(assistant.id)"

Â  Â  Â  Â  >

Â  Â  Â  Â  Â  <div class="assistant-selector-avatar">

Â  Â  Â  Â  Â  Â  <img

Â  Â  Â  Â  Â  Â  Â  v-if="assistant.imageUrl"

Â  Â  Â  Â  Â  Â  Â  :src="assistant.imageUrl"

Â  Â  Â  Â  Â  Â  Â  :alt="assistant.name"

Â  Â  Â  Â  Â  Â  Â  class="assistant-image"

Â  Â  Â  Â  Â  Â  />

Â  Â  Â  Â  Â  Â  <div v-else class="assistant-placeholder">

Â  Â  Â  Â  Â  Â  Â  {{ assistant.name ? assistant.name.charAt(0).toUpperCase() : 'A' }}

Â  Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  Â  <span class="assistant-selector-name">{{ assistant.name }}</span>

Â  Â  Â  Â  </div>

Â  Â  Â  </div>

Â  Â  </div>

Â  Â  <div class="message-display-area" ref="messageAreaRef">

Â  Â  Â  <div

Â  Â  Â  Â  v-for="message in messages"

Â  Â  Â  Â  :key="message.id"

Â  Â  Â  Â  :class="[

Â  Â  Â  Â  Â  'message-container',

Â  Â  Â  Â  Â  message.sender === 'User'

Â  Â  Â  Â  Â  Â  ? 'user-container'

Â  Â  Â  Â  Â  Â  : message.sender === 'AI'

Â  Â  Â  Â  Â  Â  Â  ? 'ai-container'

Â  Â  Â  Â  Â  Â  Â  : 'system-container',

Â  Â  Â  Â  ]"

Â  Â  Â  Â  @click="message.sender === 'AI' ? handleMessageClick(message.text) : null"

Â  Â  Â  Â  :title="message.sender === 'AI' ? 'Click to read aloud' : ''"

Â  Â  Â  >

Â  Â  Â  Â  <div class="avatar-placeholder" :title="message.sender">

Â  Â  Â  Â  Â  {{ message.sender === 'User' ? 'U' : 'AI' }}

Â  Â  Â  Â  </div>

Â  Â  Â  Â  <div

Â  Â  Â  Â  Â  :class="[

Â  Â  Â  Â  Â  Â  'message',

Â  Â  Â  Â  Â  Â  message.sender === 'User'

Â  Â  Â  Â  Â  Â  Â  ? 'user-message'

Â  Â  Â  Â  Â  Â  Â  : message.sender === 'AI'

Â  Â  Â  Â  Â  Â  Â  Â  ? 'ai-message'

Â  Â  Â  Â  Â  Â  Â  Â  : 'system-message',

Â  Â  Â  Â  Â  Â  { 'error-message-style': message.isError }, // Add class if message is an error

Â  Â  Â  Â  Â  ]"

Â  Â  Â  Â  >

Â  Â  Â  Â  Â  <img

Â  Â  Â  Â  Â  Â  v-if="message.imagePreviewUrl"

Â  Â  Â  Â  Â  Â  :src="message.imagePreviewUrl"

Â  Â  Â  Â  Â  Â  alt="Sent image thumbnail"

Â  Â  Â  Â  Â  Â  class="message-image-thumbnail"

Â  Â  Â  Â  Â  />

Â  Â  Â  Â  Â  <span class="message-text">

Â  Â  Â  Â  Â  Â  <template v-for="(segment, index) in processMessageText(message.text)" :key="index">

Â  Â  Â  Â  Â  Â  Â  <a

Â  Â  Â  Â  Â  Â  Â  Â  v-if="segment.type === 'link'"

Â  Â  Â  Â  Â  Â  Â  Â  :href="segment.url"

Â  Â  Â  Â  Â  Â  Â  Â  target="\_blank"

Â  Â  Â  Â  Â  Â  Â  Â  rel="noopener noreferrer"

Â  Â  Â  Â  Â  Â  Â  Â  @click.stop

Â  Â  Â  Â  Â  Â  Â  >

Â  Â  Â  Â  Â  Â  Â  Â  {{ segment.text }}

Â  Â  Â  Â  Â  Â  Â  </a>

Â  Â  Â  Â  Â  Â  Â  <span v-else>{{ segment.text }}</span>

Â  Â  Â  Â  Â  Â  </template>

Â  Â  Â  Â  Â  </span>

Â  Â  Â  Â  Â  <span class="timestamp">{{ formatTimestamp(message.timestamp) }}</span>

Â  Â  Â  Â  Â  <button

Â  Â  Â  Â  Â  Â  v-if="message.sender === 'AI' && !message.isError"

Â  Â  Â  Â  Â  Â  @click.stop="copyText(message.text, $event)"

Â  Â  Â  Â  Â  Â  class="copy-button"

Â  Â  Â  Â  Â  Â  title="Copy response"

Â  Â  Â  Â  Â  >

Â  Â  Â  Â  Â  Â  ğŸ“‹

Â  Â  Â  Â  Â  </button>

Â  Â  Â  Â  </div>

Â  Â  Â  </div>

Â  Â  Â  <p v-if="messages.length === 0 && !isLoading" class="placeholder-message">

Â  Â  Â  Â  No messages yet. Start the conversation{{

Â  Â  Â  Â  Â  activeAssistant?.name ? ` with ${activeAssistant.name}` : ''

Â  Â  Â  Â  }}!

Â  Â  Â  </p>

Â  Â  </div>

Â  Â  <div v-if="selectedImagePreview" class="image-preview-area">

Â  Â  Â  <img :src="selectedImagePreview" alt="Selected image preview" class="image-preview" />

Â  Â  Â  <button @click="removeSelectedImage" class="remove-image-button" title="Remove image">

Â  Â  Â  Â  âœ–

Â  Â  Â  </button>

Â  Â  </div>

Â  Â  <div class="input-area">

Â  Â  Â  <div class="loading-indicator-visual-container" v-if="isLoading">

Â  Â  Â  Â  <div class="loading-indicator-visual"></div>

Â  Â  Â  </div>

Â  Â  Â  <input

Â  Â  Â  Â  type="file"

Â  Â  Â  Â  ref="fileInputRef"

Â  Â  Â  Â  @change="handleFileSelected"

Â  Â  Â  Â  accept="image/\*"

Â  Â  Â  Â  style="display: none"

Â  Â  Â  />

Â  Â  Â  <button

Â  Â  Â  Â  @click="triggerFileInput"

Â  Â  Â  Â  class="icon-button"

Â  Â  Â  Â  aria-label="Attach file"

Â  Â  Â  Â  title="Attach file"

Â  Â  Â  Â  :disabled="isLoading"

Â  Â  Â  >

Â  Â  Â  Â  ğŸ“

Â  Â  Â  </button>

Â  Â  Â  <button

Â  Â  Â  Â  @click="toggleListening"

Â  Â  Â  Â  :class="['icon-button', isListening ? 'listening' : '']"

Â  Â  Â  Â  aria-label="Use voice input"

Â  Â  Â  Â  title="Use voice input"

Â  Â  Â  Â  :disabled="isLoading"

Â  Â  Â  >

Â  Â  Â  Â  <span v-if="!isListening">ğŸ™ï¸</span>

Â  Â  Â  Â  <span v-else>ğŸ”˜</span>

Â  Â  Â  </button>

Â  Â  Â  <textarea

Â  Â  Â  Â  ref="inputAreaRef"

Â  Â  Â  Â  v-model="userInput"

Â  Â  Â  Â  :placeholder="currentPlaceholder"

Â  Â  Â  Â  rows="1"

Â  Â  Â  Â  @input="autoGrowTextarea"

Â  Â  Â  Â  @keydown.enter.prevent="sendMessage"

Â  Â  Â  Â  :disabled="isLoading"

Â  Â  Â  Â  aria-label="Chat message input"

Â  Â  Â  ></textarea>

Â  Â  Â  <button

Â  Â  Â  Â  ref="sendButtonRef"

Â  Â  Â  Â  @click="sendMessage"

Â  Â  Â  Â  :disabled="isLoading || (!userInput.trim() && !selectedFile)"

Â  Â  Â  Â  aria-label="Send message"

Â  Â  Â  Â  class="send-button icon-button send-button-plasma"

Â  Â  Â  Â  title="Send message"

Â  Â  Â  >

Â  Â  Â  Â  â¤

Â  Â  Â  </button>

Â  Â  Â  <button

Â  Â  Â  Â  @click="toggleTts"

Â  Â  Â  Â  :class="['tts-button', 'icon-button', isTtsEnabled ? 'tts-on' : 'tts-off']"

Â  Â  Â  Â  :aria-pressed="isTtsEnabled"

Â  Â  Â  Â  aria-label="Toggle text to speech"

Â  Â  Â  Â  :disabled="isLoading"

Â  Â  Â  >

Â  Â  Â  Â  <span v-if="isTtsEnabled" title="Speech ON">ğŸ”Š</span>

Â  Â  Â  Â  <span v-else title="Speech OFF">ğŸ”‡</span>

Â  Â  Â  </button>

Â  Â  </div>

Â  </div>

</template>

<script setup>

// *** FULL SCRIPT SECTION - Identical to the last fully correct version ***

import { ref, nextTick, computed, onMounted, onUnmounted, watch } from 'vue'

import { useAssistantsStore } from '@/stores/assistantsStore'

import { useSettingsStore } from '@/stores/settingsStore' // Import settings store

import { storeToRefs } from 'pinia'



// --- Props ---

const props = defineProps({

Â  assistantConfig: { type: Object, required: false, default: null },

})



// --- Store Setup ---

const assistantsStore = useAssistantsStore()

const settingsStore = useSettingsStore() // Get settings store instance



// Use storeToRefs for reactive access

const { assistants: availableAssistants, getAssistantById } = storeToRefs(assistantsStore)

const { isTtsEnabled, selectedVoiceUri } = storeToRefs(settingsStore) // Get reactive state from settings store



// --- Refs ---

const messageAreaRef = ref(null)

const inputAreaRef = ref(null)

const sendButtonRef = ref(null)

const fileInputRef = ref(null)



// --- Reactive State ---

const userInput = ref('')

const messages = ref([]) // Stores { id, text, sender, timestamp, imagePreviewUrl?, isError? }

const isLoading = ref(false)

// isTtsEnabled removed - using store's ref now

const synth = window.speechSynthesis

const ttsSupported = ref(!!synth)

const availableVoices = ref([]) // Store fetched voices locally in ChatView for speaking

const selectedImagePreview = ref(null) // Holds the data URL for image preview

const selectedFile = ref(null) // Holds the actual File object

const selectedAssistantId = ref(null) // NEW: Track selected assistant ID (null for default)



// --- Speech Recognition State ---

const isListening = ref(false)

const recognition = ref(null)

const speechSupported = ref(false)

// -----------------------------



// --- Computed Properties ---

// Determines the currently active assistant (either from prop or selection)

const activeAssistant = computed(() => {

Â  if (props.assistantConfig) return props.assistantConfig

Â  if (selectedAssistantId.value) return getAssistantById.value(selectedAssistantId.value)

Â  return null

})

const activeAssistantName = computed(() => activeAssistant.value?.name || 'Default AI')

const chatHistoryForApi = computed(() =>

Â  messages.value

Â  Â  .filter((msg) => (msg.sender === 'User' || msg.sender === 'AI') && !msg.isError) // Exclude errors

Â  Â  .map((msg) => ({

Â  Â  Â  role: msg.sender === 'User' ? 'user' : 'model',

Â  Â  Â  parts: [{ text: msg.text }],

Â  Â  })),

)



// --- Animated Placeholder ---

const placeholders = [

Â  'Type your message or use the mic...',

Â  'Ask me anything...',

Â  'Attach an image and ask about it...',

Â  'Write a story about a dragon...',

Â  'Explain quantum physics simply...',

]

const currentPlaceholder = ref(placeholders[0])

let placeholderInterval = null



// --- Lifecycle Hooks ---

onMounted(() => {

Â  // Setup placeholder interval (unchanged)

Â  let placeholderIndex = 0

Â  placeholderInterval = setInterval(() => {

Â  Â  placeholderIndex = (placeholderIndex + 1) % placeholders.length

Â  Â  if (!userInput.value && !selectedImagePreview.value) {

Â  Â  Â  const basePlaceholder = activeAssistant.value

Â  Â  Â  Â  ? `Ask ${activeAssistant.value.name}...`

Â  Â  Â  Â  : placeholders[placeholderIndex]

Â  Â  Â  currentPlaceholder.value = basePlaceholder

Â  Â  } else if (!selectedImagePreview.value) {

Â  Â  Â  const defaultText = activeAssistant.value

Â  Â  Â  Â  ? `Continue chatting with ${activeAssistant.value.name}...`

Â  Â  Â  Â  : placeholders[0]

Â  Â  Â  currentPlaceholder.value = defaultText

Â  Â  }

Â  }, 3000)

Â  setupSpeechRecognition()

Â  // Fetch TTS voices (unchanged)

Â  if (ttsSupported.value && synth) {

Â  Â  const loadVoices = () => {

Â  Â  Â  availableVoices.value = synth.getVoices().sort((a, b) => a.name.localeCompare(b.name))

Â  Â  Â  if (availableVoices.value.length > 0) {

Â  Â  Â  Â  console.log('ChatView: Voices loaded:', availableVoices.value.length)

Â  Â  Â  Â  if (synth.onvoiceschanged !== undefined) synth.onvoiceschanged = null

Â  Â  Â  } else {

Â  Â  Â  Â  setTimeout(() => {

Â  Â  Â  Â  Â  const vr = synth.getVoices()

Â  Â  Â  Â  Â  if (vr.length > 0) {

Â  Â  Â  Â  Â  Â  availableVoices.value = vr.sort((a, b) => a.name.localeCompare(b.name))

Â  Â  Â  Â  Â  Â  console.log('ChatView: Voices loaded retry:', availableVoices.value.length)

Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  console.warn('ChatView: Voices not loaded after retry.')

Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }, 500)

Â  Â  Â  }

Â  Â  }

Â  Â  if (synth.getVoices().length > 0) loadVoices()

Â  Â  else if (synth.onvoiceschanged !== undefined) synth.onvoiceschanged = loadVoices

Â  Â  else setTimeout(loadVoices, 500)

Â  }

Â  // Initial setup based on props (unchanged)

Â  if (props.assistantConfig) {

Â  Â  selectedAssistantId.value = props.assistantConfig.id

Â  Â  addMessage({ text: `Testing: ${props.assistantConfig.name}.` }, 'System')

Â  } else {

Â  Â  console.log('ChatView mounted (main view).')

Â  }

})

onUnmounted(() => {

Â  // Cleanup (unchanged)

Â  clearInterval(placeholderInterval)

Â  if (synth) synth.cancel()

Â  if (recognition.value) recognition.value.abort()

})



// --- Watcher (unchanged) ---

watch(

Â  () => props.assistantConfig,

Â  (newConfig, oldConfig) => {

Â  Â  if (newConfig !== oldConfig && props.assistantConfig) {

Â  Â  Â  messages.value = []

Â  Â  Â  selectedAssistantId.value = newConfig?.id || null

Â  Â  Â  if (newConfig) addMessage({ text: `Testing: ${newConfig.name}.` }, 'System')

Â  Â  Â  userInput.value = ''

Â  Â  Â  removeSelectedImage()

Â  Â  Â  scrollToBottom('auto')

Â  Â  }

Â  },

Â  { immediate: false },

)



// --- Assistant Selection (unchanged) ---

const selectAssistant = (assistantId) => {

Â  if (props.assistantConfig) return

Â  if (selectedAssistantId.value === assistantId) return

Â  selectedAssistantId.value = assistantId

Â  messages.value = []

Â  const selAsst = activeAssistant.value

Â  addMessage({ text: `Switched to ${selAsst?.name || 'Default AI'}.` }, 'System')

Â  userInput.value = ''

Â  removeSelectedImage()

Â  scrollToBottom('auto')

Â  inputAreaRef.value?.focus()

Â  const p = selAsst ? `Ask ${selAsst.name}...` : placeholders[0]

Â  currentPlaceholder.value = p

}



// --- Speech Recognition --- (Full implementation - unchanged)

const setupSpeechRecognition = () => {

Â  const SR = window.SpeechRecognition || window.webkitSpeechRecognition

Â  if (SR) {

Â  Â  speechSupported.value = true

Â  Â  try {

Â  Â  Â  recognition.value = new SR()

Â  Â  Â  recognition.value.continuous = false

Â  Â  Â  recognition.value.lang = 'en-US'

Â  Â  Â  recognition.value.interimResults = false

Â  Â  Â  recognition.value.maxAlternatives = 1

Â  Â  Â  recognition.value.onresult = (e) => {

Â  Â  Â  Â  const t = e.results?.[0]?.[0]?.transcript

Â  Â  Â  Â  if (t) {

Â  Â  Â  Â  Â  userInput.value += (userInput.value ? ' ' : '') + t

Â  Â  Â  Â  Â  nextTick(() => {

Â  Â  Â  Â  Â  Â  if (inputAreaRef.value) autoGrowTextarea({ target: inputAreaRef.value })

Â  Â  Â  Â  Â  })

Â  Â  Â  Â  }

Â  Â  Â  }

Â  Â  Â  recognition.value.onerror = (e) => {

Â  Â  Â  Â  console.error('Speech Err:', e.error, e.message)

Â  Â  Â  Â  let m = `Speech Err: ${e.error}`

Â  Â  Â  Â  if (['not-allowed', 'service-not-allowed'].includes(e.error)) m = 'Mic access denied.'

Â  Â  Â  Â  else if (e.error === 'no-speech') m = 'No speech.'

Â  Â  Â  Â  else if (e.error === 'audio-capture') m = 'Mic problem.'

Â  Â  Â  Â  addMessage({ isError: true, text: m }, 'System')

Â  Â  Â  Â  isListening.value = false

Â  Â  Â  }

Â  Â  Â  recognition.value.onstart = () => {

Â  Â  Â  Â  isListening.value = true

Â  Â  Â  }

Â  Â  Â  recognition.value.onend = () => {

Â  Â  Â  Â  isListening.value = false

Â  Â  Â  Â  nextTick(() => inputAreaRef.value?.focus())

Â  Â  Â  }

Â  Â  } catch (e) {

Â  Â  Â  console.error('SR init Err:', e)

Â  Â  Â  speechSupported.value = false

Â  Â  Â  addMessage({ isError: true, text: 'Speech init failed.' }, 'System')

Â  Â  }

Â  } else {

Â  Â  speechSupported.value = false

Â  }

}

const startListening = () => {

Â  if (!speechSupported.value || !recognition.value || isListening.value) return

Â  try {

Â  Â  recognition.value.start()

Â  } catch (e) {

Â  Â  console.error(`Start Err: ${e.name}`, e)

Â  Â  if (e.name !== 'InvalidStateError')

Â  Â  Â  addMessage({ isError: true, text: `Voice start Err: ${e.message}` }, 'System')

Â  Â  isListening.value = false

Â  }

}

const stopListening = () => {

Â  if (!speechSupported.value || !recognition.value || !isListening.value) return

Â  try {

Â  Â  recognition.value.stop()

Â  } catch (e) {

Â  Â  console.warn('Stop Err:', e)

Â  Â  isListening.value = false

Â  }

}

const toggleListening = () => {

Â  if (!speechSupported.value) {

Â  Â  addMessage({ isError: true, text: 'Voice not supported.' }, 'System')

Â  Â  return

Â  }

Â  if (isListening.value) stopListening()

Â  else startListening()

}



// --- File Input Handling --- (Full implementation - unchanged)

const triggerFileInput = () => {

Â  fileInputRef.value?.click()

}

const readFileAsBase64 = (file) => {

Â  return new Promise((res, rej) => {

Â  Â  const r = new FileReader()

Â  Â  r.onload = () => {

Â  Â  Â  const b = r.result?.toString().split(',')[1]

Â  Â  Â  if (b) res({ base64Data: b, mimeType: file.type })

Â  Â  Â  else rej(new Error('Base64 read fail.'))

Â  Â  }

Â  Â  r.onerror = (e) => rej(e)

Â  Â  r.readAsDataURL(file)

Â  })

}

const handleFileSelected = async (event) => {

Â  const f = event.target.files?.[0]

Â  if (!f) {

Â  Â  removeSelectedImage()

Â  Â  return

Â  }

Â  if (!f.type.startsWith('image/')) {

Â  Â  addMessage({ isError: true, text: `Invalid type: ${f.name}` }, 'System')

Â  Â  removeSelectedImage()

Â  Â  return

Â  }

Â  const maxMB = 4

Â  if (f.size > maxMB * 1024 * 1024) {

Â  Â  addMessage({ isError: true, text: `Too large (>${maxMB}MB): ${f.name}` }, 'System')

Â  Â  removeSelectedImage()

Â  Â  return

Â  }

Â  selectedFile.value = f

Â  const pR = new FileReader()

Â  pR.onload = (e) => {

Â  Â  selectedImagePreview.value = e.target?.result

Â  Â  currentPlaceholder.value = 'Image selected.'

Â  }

Â  pR.onerror = (e) => {

Â  Â  console.error('Preview Err:', e)

Â  Â  addMessage({ isError: true, text: 'Preview read error.' }, 'System')

Â  Â  removeSelectedImage()

Â  }

Â  pR.readAsDataURL(f)

Â  event.target.value = null

}

const removeSelectedImage = () => {

Â  selectedImagePreview.value = null

Â  selectedFile.value = null

Â  if (fileInputRef.value) fileInputRef.value.value = null

Â  if (!userInput.value) {

Â  Â  const p = activeAssistant.value ? `Ask ${activeAssistant.value.name}...` : placeholders[0]

Â  Â  currentPlaceholder.value = p

Â  }

}



// --- Textarea Auto-Grow --- (Full implementation - unchanged)

const autoGrowTextarea = (event) => {

Â  const t = event.target

Â  t.style.height = 'auto'

Â  const maxH = 150

Â  t.style.height = `${Math.min(t.scrollHeight, maxH)}px`

}



// --- Text-to-Speech (TTS) --- (Full implementation - unchanged, uses store state)

const speakText = (text) => {

Â  if (!ttsSupported.value || !synth || !text || !isTtsEnabled.value) return

Â  if (synth.speaking) {

Â  Â  synth.cancel()

Â  Â  setTimeout(() => {

Â  Â  Â  trySpeak(text)

Â  Â  }, 50)

Â  } else {

Â  Â  trySpeak(text)

Â  }

}

const trySpeak = (text) => {

Â  const u = new SpeechSynthesisUtterance(text)

Â  if (selectedVoiceUri.value && availableVoices.value.length > 0) {

Â  Â  const v = availableVoices.value.find((v) => v.voiceURI === selectedVoiceUri.value)

Â  Â  if (v) u.voice = v

Â  Â  else console.warn(`Voice URI ${selectedVoiceUri.value} not found.`)

Â  }

Â  u.onerror = (e) => {

Â  Â  console.error(`TTS Err: ${e.error}`)

Â  Â  if (!['interrupted', 'canceled'].includes(e.error))

Â  Â  Â  addMessage({ isError: true, text: `Speech Err: ${e.error}` }, 'System')

Â  }

Â  synth.speak(u)

}

const handleMessageClick = (text) => {

Â  if (isTtsEnabled.value) speakText(text)

}

const toggleTts = () => {

Â  if (!ttsSupported.value) {

Â  Â  addMessage({ isError: true, text: 'TTS not supported.' }, 'System')

Â  Â  return

Â  }

Â  settingsStore.setTtsEnabled(!isTtsEnabled.value)

Â  if (!settingsStore.isTtsEnabled && synth.speaking) synth.cancel()

}



// --- Timestamp Formatting --- (Full implementation - unchanged)

const formatTimestamp = (ts) => {

Â  if (!ts) return ''

Â  try {

Â  Â  return new Date(ts).toLocaleTimeString([], { hour: 'numeric', minute: '2-digit', hour12: true })

Â  } catch (e) {

Â  Â  return '?'

Â  }

}



// --- Copy to Clipboard --- (Full implementation - unchanged)

const copyText = async (text, event) => {

Â  if (!navigator.clipboard) {

Â  Â  addMessage({ isError: true, text: 'Clipboard unavailable.' }, 'System')

Â  Â  return

Â  }

Â  try {

Â  Â  await navigator.clipboard.writeText(text)

Â  Â  const b = event?.currentTarget

Â  Â  if (b) {

Â  Â  Â  const o = b.innerHTML

Â  Â  Â  b.innerHTML = 'âœ…'

Â  Â  Â  b.disabled = true

Â  Â  Â  setTimeout(() => {

Â  Â  Â  Â  if (b) {

Â  Â  Â  Â  Â  b.innerHTML = o

Â  Â  Â  Â  Â  b.disabled = false

Â  Â  Â  Â  }

Â  Â  Â  }, 1500)

Â  Â  }

Â  } catch (err) {

Â  Â  console.error('Copy Err:', err)

Â  Â  addMessage({ isError: true, text: `Copy failed: ${err.message}` }, 'System')

Â  }

}



// --- Link Processing --- (Full implementation - unchanged)

const processMessageText = (text) => {

Â  if (!text) return [{ type: 'text', text: '' }]

Â  const r =

Â  Â  /(\b(https?|ftp|file):\/\/[-A-Z0-9+&@#/%?=~_|!:,.;]*[-A-Z0-9+&@#/%?=~_|])|(\bwww\.[-A-Z0-9+&@#/%?=~_|!:,.;]*[-A-Z0-9+&@#/%?=~_|])(?![^<]*?>|[^<>]*?<\/(a|button|textarea|input)[^<>]*?>)/gi

Â  const s = []

Â  let l = 0

Â  let m

Â  while ((m = r.exec(text)) !== null) {

Â  Â  if (m.index > l) s.push({ type: 'text', text: text.substring(l, m.index) })

Â  Â  let u = m[0]

Â  Â  if (!u.match(/^(https?|ftp|file):\/\//i)) u = 'https://' + u

Â  Â  s.push({ type: 'link', text: m[0], url: u })

Â  Â  l = r.lastIndex

Â  }

Â  if (l < text.length) s.push({ type: 'text', text: text.substring(l) })

Â  if (s.length === 0 && text) s.push({ type: 'text', text: text })

Â  return s

}



// --- Message Handling --- (Full implementation - unchanged, includes aiText fix)

const scrollToBottom = (behavior = 'smooth') => {

Â  nextTick(() => {

Â  Â  const el = messageAreaRef.value

Â  Â  if (el) el.scrollTo({ top: el.scrollHeight, behavior: behavior })

Â  })

}

const addMessage = (payload, sender = 'User', imagePreviewUrl = null) => {

Â  let txt = ''

Â  let snd = sender

Â  let err = false

Â  if (typeof payload === 'string') txt = payload

Â  else if (typeof payload === 'object' && payload !== null) {

Â  Â  err = payload.isError === true

Â  Â  snd = payload.sender || sender

Â  Â  if (err) {

Â  Â  Â  txt = payload.text || 'Error.'

Â  Â  Â  snd = 'System'

Â  Â  } else if (typeof payload.aiText === 'string') {

Â  Â  Â  txt = payload.aiText

Â  Â  Â  snd = 'AI'

Â  Â  } else if (snd === 'System' && typeof payload.text === 'string') txt = payload.text

Â  Â  else {

Â  Â  Â  txt = JSON.stringify(payload)

Â  Â  Â  snd = 'System'

Â  Â  Â  err = true

Â  Â  }

Â  } else return

Â  const trimTxt = txt.trim()

Â  if (trimTxt === '' && !imagePreviewUrl && snd !== 'System') {

Â  Â  if (!(snd === 'User' && txt.startsWith('[Sent Image:'))) return

Â  }

Â  const newMsg = {

Â  Â  id: Date.now() + Math.random(),

Â  Â  text: trimTxt,

Â  Â  sender: snd,

Â  Â  timestamp: Date.now(),

Â  Â  imagePreviewUrl: imagePreviewUrl,

Â  Â  isError: err,

Â  }

Â  messages.value.push(newMsg)

Â  scrollToBottom('smooth')

Â  if (snd === 'AI' && !err && isTtsEnabled.value && newMsg.text) speakText(newMsg.text)

}



// --- API Call Logic --- (Full implementation - unchanged)

const callBackendApi = async (inputText, imageFile) => {

Â  const URL = '/.netlify/functions/call-gemini'

Â  let imgData = null

Â  if (imageFile) {

Â  Â  try {

Â  Â  Â  imgData = await readFileAsBase64(imageFile)

Â  Â  } catch (e) {

Â  Â  Â  return { isError: true, text: 'Image processing error.' }

Â  Â  }

Â  }

Â  const cfg = activeAssistant.value

Â  const instr = cfg?.instructions || null

Â  const payload = {

Â  Â  history: chatHistoryForApi.value,

Â  Â  inputText: inputText.trim(),

Â  Â  imageFile: imgData,

Â  Â  assistantInstructions: instr,

Â  }

Â  console.log('Sending payload structure:', {

Â  Â  history: `(${payload.history?.length || 0})`,

Â  Â  input: !!payload.inputText,

Â  Â  img: !!payload.imageFile,

Â  Â  instr: !!payload.assistantInstructions,

Â  })

Â  try {

Â  Â  const r = await fetch(URL, {

Â  Â  Â  method: 'POST',

Â  Â  Â  headers: { 'Content-Type': 'application/json' },

Â  Â  Â  body: JSON.stringify(payload),

Â  Â  })

Â  Â  const rt = await r.text()

Â  Â  if (!r.ok) {

Â  Â  Â  let e = `HTTP ${r.status}`

Â  Â  Â  try {

Â  Â  Â  Â  const p = JSON.parse(rt)

Â  Â  Â  Â  e = p.error || `${e}: ${rt.substring(0, 100)}`

Â  Â  Â  } catch (err) {

Â  Â  Â  Â  e += `: ${rt.substring(0, 100)}`

Â  Â  Â  }

Â  Â  Â  throw new Error(e)

Â  Â  }

Â  Â  let d

Â  Â  try {

Â  Â  Â  d = JSON.parse(rt)

Â  Â  } catch (e) {

Â  Â  Â  throw new Error(`Invalid JSON: ${rt.substring(0, 100)}`)

Â  Â  }

Â  Â  if (d.error) throw new Error(d.error)

Â  Â  if (d.blockReason && !['STOP', 'MAX_TOKENS'].includes(d.blockReason))

Â  Â  Â  return { isError: true, text: `Blocked: ${d.blockReason}` }

Â  Â  if (typeof d.aiText === 'string') return d

Â  Â  else return { isError: true, text: '[Invalid AI content]' }

Â  } catch (e) {

Â  Â  return { isError: true, text: `API Error: ${e.message}` }

Â  }

}



// --- Send Button Flash --- (Keep original version)

const triggerSendFlash = () => {

Â  const btn = sendButtonRef.value

Â  if (!btn) return

Â  btn.classList.remove('flash-active')

Â  void btn.offsetWidth

Â  btn.classList.add('flash-active')

Â  setTimeout(() => {

Â  Â  if (btn) btn.classList.remove('flash-active')

Â  }, 300)

}



// --- Send Message Action --- (Full implementation, no thinking message)

const sendMessage = async () => {

Â  const txt = userInput.value

Â  const file = selectedFile.value

Â  const preview = selectedImagePreview.value

Â  if (isLoading.value || (txt.trim() === '' && !file)) return

Â  /* triggerSendFlash(); Don't trigger flash if using plasma animation */ let userMsg = txt.trim()

Â  if (file && userMsg === '') userMsg = `[Sent Image: ${file.name}]`

Â  if (userMsg !== '' || preview) addMessage(userMsg, 'User', preview)

Â  else return

Â  const txtToSend = txt.trim()

Â  const imgToSend = file

Â  userInput.value = ''

Â  removeSelectedImage()

Â  nextTick(() => {

Â  Â  if (inputAreaRef.value) {

Â  Â  Â  inputAreaRef.value.style.height = 'auto'

Â  Â  Â  autoGrowTextarea({ target: inputAreaRef.value })

Â  Â  }

Â  Â  const p = activeAssistant.value ? `Ask ${activeAssistant.value.name}...` : placeholders[0]

Â  Â  currentPlaceholder.value = p

Â  })

Â  isLoading.value = true

Â  scrollToBottom('smooth')

Â  const apiResp = await callBackendApi(txtToSend, imgToSend)

Â  addMessage(apiResp)

Â  isLoading.value = false

Â  nextTick(() => {

Â  Â  inputAreaRef.value?.focus()

Â  })

}

// --- End Full Script ---

</script>

<style scoped>

/* --- Styles include previous fixes + NEW icon button styles --- */

.chat-view {

Â  height: 100%;

Â  display: flex;

Â  flex-direction: column;

Â  background-color: var(--bg-main-content);

Â  color: var(--text-primary);

Â  overflow: hidden;

}

.message-display-area {

Â  flex-grow: 1;

Â  overflow-y: auto;

Â  padding: 0 1rem 1rem 1rem;

Â  background-color: var(--bg-main-content);

Â  display: flex;

Â  flex-direction: column;

}

.assistant-selector-area {

Â  padding: 0.5rem 0.5rem 0.75rem;

Â  background-color: var(--bg-input-area);

Â  border-bottom: 1px solid var(--border-color-medium);

Â  flex-shrink: 0;

Â  overflow: hidden;

Â  position: sticky;

Â  top: 0;

Â  z-index: 10;

}

.assistant-selector-row {

Â  display: flex;

Â  gap: 0.75rem;

Â  overflow-x: auto;

Â  padding-bottom: 5px;

Â  -ms-overflow-style: none;

Â  scrollbar-width: none;

}

.assistant-selector-row::-webkit-scrollbar {

Â  display: none;

}

.assistant-selector-item {

Â  display: flex;

Â  flex-direction: column;

Â  align-items: center;

Â  padding: 0.3rem 0.5rem;

Â  border-radius: 8px;

Â  border: 2px solid transparent;

Â  cursor: pointer;

Â  transition:

Â  Â  background-color 0.2s ease,

Â  Â  border-color 0.2s ease;

Â  min-width: 70px;

Â  text-align: center;

Â  outline: none;

}

.assistant-selector-item:hover {

Â  background-color: var(--bg-button-secondary-hover);

}

.assistant-selector-item:focus-visible {

Â  border-color: var(--accent-color-secondary);

Â  box-shadow: 0 0 0 1px var(--accent-color-secondary);

}

.assistant-selector-item.selected {

Â  border-color: var(--accent-color-primary);

Â  background-color: color-mix(in srgb, var(--accent-color-primary) 15%, transparent);

}

.assistant-selector-avatar {

Â  width: 40px;

Â  height: 40px;

Â  border-radius: 50%;

Â  overflow: hidden;

Â  background-color: var(--bg-sidebar);

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  border: 1px solid var(--border-color-light);

Â  margin-bottom: 0.3rem;

Â  flex-shrink: 0;

}

.assistant-selector-avatar .assistant-image {

Â  width: 100%;

Â  height: 100%;

Â  object-fit: cover;

}

.assistant-selector-avatar .assistant-placeholder {

Â  width: 100%;

Â  height: 100%;

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  font-size: 1.3em;

Â  font-weight: 600;

Â  color: var(--text-secondary);

Â  background-color: var(--bg-sidebar);

Â  border-radius: 50%;

Â  user-select: none;

}

.assistant-placeholder.default-placeholder {

Â  font-size: 1.5em;

Â  font-weight: bold;

}

.assistant-selector-name {

Â  font-size: 0.75em;

Â  color: var(--text-secondary);

Â  white-space: nowrap;

Â  overflow: hidden;

Â  text-overflow: ellipsis;

Â  max-width: 65px;

}

.assistant-selector-item.selected .assistant-selector-name {

Â  color: var(--text-primary);

Â  font-weight: 500;

}

.message-container {

Â  display: flex;

Â  margin-bottom: 0.75rem;

Â  max-width: 85%;

Â  opacity: 0;

Â  transform: translateY(10px);

Â  animation: fadeIn 0.3s ease forwards;

Â  position: relative;

}

.ai-container {

Â  cursor: pointer;

}

.user-container {

Â  align-self: flex-end;

Â  margin-left: auto;

Â  flex-direction: row-reverse;

}

.ai-container,

.system-container {

Â  align-self: flex-start;

Â  margin-right: auto;

Â  flex-direction: row;

}

@keyframes fadeIn {

Â  to {

Â  Â  opacity: 1;

Â  Â  transform: translateY(0);

Â  }

}

.avatar-placeholder {

Â  width: 32px;

Â  height: 32px;

Â  border-radius: 50%;

Â  background-color: var(--bg-avatar-ai);

Â  color: var(--text-light);

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  font-weight: bold;

Â  font-size: 0.9em;

Â  flex-shrink: 0;

Â  margin-top: 4px;

Â  margin-right: 0.5rem;

Â  user-select: none;

}

.user-container .avatar-placeholder {

Â  margin-right: 0;

Â  margin-left: 0.5rem;

Â  background-color: var(--bg-avatar-user);

}

.system-container .avatar-placeholder {

Â  display: none;

}

.message {

Â  padding: 0.6rem 1rem;

Â  border-radius: 18px;

Â  word-wrap: break-word;

Â  font-family: sans-serif;

Â  line-height: 1.45;

Â  position: relative;

Â  min-width: 50px;

Â  display: flex;

Â  flex-direction: column;

Â  box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);

}

.user-message {

Â  background-color: var(--bg-message-user);

Â  color: var(--text-message-user);

Â  border-bottom-right-radius: 6px;

}

.ai-message {

Â  background-color: var(--bg-message-ai);

Â  color: var(--text-message-ai);

Â  border-bottom-left-radius: 6px;

}

.message-text :deep(a) {

Â  color: var(--text-link);

Â  text-decoration: underline;

Â  text-decoration-thickness: 1px;

Â  text-underline-offset: 2px;

}

.message-text :deep(a:hover) {

Â  color: var(--text-link-hover);

Â  text-decoration: none;

}

.system-message {

Â  background-color: var(--bg-message-info);

Â  color: var(--text-secondary);

Â  width: 100%;

Â  text-align: center;

Â  font-style: italic;

Â  font-size: 0.9em;

Â  border: 1px dashed var(--border-color-medium);

Â  border-radius: 8px;

Â  padding-top: 0.8rem;

Â  padding-bottom: 0.8rem;

Â  margin-left: auto;

Â  margin-right: auto;

Â  max-width: 90%;

Â  box-shadow: none;

}

.message.error-message-style {

Â  background-color: var(--bg-message-error);

Â  color: var(--text-message-error);

Â  border: 1px solid var(--border-color-error);

Â  border-radius: 8px;

}

.system-message.error-message-style {

Â  border-style: solid;

}

.system-container {

Â  width: 100%;

Â  justify-content: center;

Â  align-self: center;

}

.message-image-thumbnail {

Â  max-width: 150px;

Â  max-height: 100px;

Â  border-radius: 8px;

Â  margin-bottom: 0.5rem;

Â  object-fit: contain;

Â  border: 1px solid var(--border-color-light);

Â  align-self: flex-start;

}

.timestamp {

Â  font-size: 0.7em;

Â  color: var(--text-timestamp);

Â  margin-top: 0.3rem;

Â  text-align: right;

Â  user-select: none;

Â  -webkit-user-select: none;

Â  width: 100%;

}

.copy-button {

Â  position: absolute;

Â  bottom: 2px;

Â  right: -30px;

Â  background-color: transparent;

Â  border: none;

Â  color: var(--text-secondary);

Â  border-radius: 50%;

Â  width: 24px;

Â  height: 24px;

Â  font-size: 1em;

Â  cursor: pointer;

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  opacity: 0;

Â  transition:

Â  Â  opacity 0.2s ease,

Â  Â  color 0.2s ease;

Â  z-index: 1;

Â  padding: 0;

}

.ai-container:hover .copy-button {

Â  opacity: 0.6;

}

.copy-button:hover {

Â  opacity: 1;

Â  color: var(--text-primary);

}

.copy-button:disabled {

Â  cursor: default;

Â  opacity: 0.8;

}

.placeholder-message {

Â  color: var(--text-placeholder);

Â  font-style: italic;

Â  font-family: sans-serif;

Â  text-align: center;

Â  margin: 2rem auto;

}

.image-preview-area {

Â  padding: 0.5rem 0.75rem 0.5rem;

Â  margin: 0 0.75rem;

Â  background-color: var(--bg-sidebar);

Â  border: 1px solid var(--border-color-medium);

Â  border-bottom: none;

Â  border-radius: 8px 8px 0 0;

Â  display: flex;

Â  align-items: center;

Â  gap: 0.5rem;

Â  flex-shrink: 0;

}

.image-preview {

Â  max-height: 50px;

Â  max-width: 80px;

Â  border-radius: 4px;

Â  border: 1px solid var(--border-color-light);

Â  object-fit: cover;

}

.remove-image-button {

Â  background: rgba(0, 0, 0, 0.5);

Â  color: white;

Â  border: none;

Â  border-radius: 50%;

Â  width: 20px;

Â  height: 20px;

Â  font-size: 0.8em;

Â  line-height: 1;

Â  cursor: pointer;

Â  padding: 0;

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  transition: background-color 0.2s ease;

}

.remove-image-button:hover {

Â  background: rgba(0, 0, 0, 0.7);

}

.input-area {

Â  display: flex;

Â  align-items: flex-end;

Â  padding: 0.75rem;

Â  background-color: var(--bg-input-area);

Â  flex-shrink: 0;

Â  gap: 0.5rem;

Â  border-radius: 0;

Â  border-top: none;

Â  position: relative;

}

.chat-view:has(.image-preview-area) .input-area {

Â  border-top: 1px solid var(--border-color-medium);

}

.input-area textarea {

Â  flex-grow: 1;

Â  padding: 0.5rem 0.75rem;

Â  border: 1px solid var(--border-color-medium);

Â  border-radius: 15px;

Â  resize: none;

Â  font-family: sans-serif;

Â  font-size: 1em;

Â  min-height: 40px;

Â  max-height: 150px;

Â  overflow-y: auto;

Â  line-height: 1.4;

Â  background-color: var(--bg-input-field);

Â  color: var(--text-primary);

Â  transition:

Â  Â  border-color 0.2s ease,

Â  Â  box-shadow 0.2s ease;

}

.input-area textarea::placeholder {

Â  color: var(--text-placeholder);

}

.input-area textarea:hover:not(:focus):not(:disabled) {

Â  border-color: var(--accent-color-primary);

}

.input-area textarea:focus {

Â  outline: none;

Â  border-color: var(--accent-color-primary);

Â  box-shadow: var(

Â  Â  --input-focus-shadow,

Â  Â  0 0 0 2px color-mix(in srgb, var(--accent-color-primary) 50%, transparent)

Â  );

}

.input-area textarea:disabled {

Â  background-color: color-mix(in srgb, var(--bg-input-field) 50%, var(--bg-input-area));

Â  cursor: not-allowed;

Â  opacity: 0.7;

}

.input-area button {

Â  padding: 0.5rem;

Â  border: none;

Â  border-radius: 50%;

Â  cursor: pointer;

Â  min-height: 40px;

Â  min-width: 40px;

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  font-size: 1.2em;

Â  flex-shrink: 0;

Â  transition:

Â  Â  background-color 0.2s ease,

Â  Â  opacity 0.2s ease,

Â  Â  transform 0.1s ease,

Â  Â  box-shadow 0.2s ease;

}

.input-area button:disabled {

Â  cursor: not-allowed;

Â  opacity: 0.6;

Â  animation: none !important;

Â  box-shadow: none !important;

}

.input-area button:active:not(:disabled) {

Â  transform: scale(0.95);

}

.icon-button {

Â  background-color: var(--bg-button-secondary);

Â  color: var(--text-button-secondary);

}

.icon-button:hover:not(:disabled) {

Â  background-color: var(--bg-button-secondary-hover);

}

.icon-button.listening {

Â  background-color: var(--bg-button-listening);

Â  color: var(--text-button-listening);

Â  animation: pulse-red 1.5s infinite ease-in-out;

}

@keyframes pulse-red {

Â  0%,

Â  100% {

Â  Â  box-shadow: 0 0 0 0px color-mix(in srgb, var(--bg-button-listening) 70%, transparent);

Â  }

Â  50% {

Â  Â  box-shadow: 0 0 0 5px color-mix(in srgb, var(--bg-button-listening) 0%, transparent);

Â  }

}



/* --- Send Button --- */

.send-button {

Â  /* Inherits .icon-button size/shape/etc */

Â  background-color: var(--bg-button-primary);

Â  color: var(--text-button-primary);

Â  font-size: 1.5em; /* Make arrow larger */

Â  padding: 0.5rem 0.5rem; /* Adjusted padding */

Â  line-height: 1; /* Better vertical centering for arrow */

}

.send-button:hover:not(:disabled) {

Â  background-color: var(--bg-button-primary-hover);

}

.send-button:disabled {

Â  background-color: color-mix(in srgb, var(--bg-button-primary) 50%, var(--bg-input-area));

}

/* Plasma Animation for Send Button */

.send-button-plasma:not(:disabled) {

Â  animation: plasma-arrow-pulse 2s infinite ease-in-out;

Â  box-shadow: 0 0 5px 1px color-mix(in srgb, var(--accent-color-primary) 30%, transparent);

}

@keyframes plasma-arrow-pulse {

Â  0% {

Â  Â  box-shadow: 0 0 5px 1px color-mix(in srgb, var(--accent-color-primary) 30%, transparent);

Â  Â  transform: scale(1);

Â  }

Â  50% {

Â  Â  box-shadow: 0 0 10px 3px color-mix(in srgb, var(--accent-color-primary) 60%, transparent);

Â  Â  transform: scale(1.05);

Â  }

Â  100% {

Â  Â  box-shadow: 0 0 5px 1px color-mix(in srgb, var(--accent-color-primary) 30%, transparent);

Â  Â  transform: scale(1);

Â  }

}



/* --- TTS Button --- */

.tts-button {

Â  /* Inherits .icon-button size/shape */

Â  background-color: var(--bg-button-secondary); /* Off state */

Â  color: var(--text-button-secondary);

Â  font-size: 1.1em;

Â  border: 1px solid transparent; /* Add transparent border to maintain size */

}

.tts-button.tts-on {

Â  /* ON state */

Â  background-color: var(--accent-color-primary); /* Green background */

Â  color: var(--bg-input-area); /* Dark icon on green */

Â  border-color: var(--accent-color-primary);

}

.tts-button:hover:not(:disabled) {

Â  /* Slightly darker secondary for OFF hover */

Â  background-color: var(--bg-button-secondary-hover);

Â  border-color: transparent;

}

.tts-button.tts-on:hover:not(:disabled) {

Â  /* Slightly darker green for ON hover */

Â  background-color: color-mix(in srgb, var(--accent-color-primary) 90%, #000000);

Â  border-color: color-mix(in srgb, var(--accent-color-primary) 90%, #000000);

Â  color: var(--bg-input-area);

}



/* --- Loading Indicator Styles (Enhanced) --- */

.loading-indicator-visual-container {

Â  position: absolute;

Â  top: 0;

Â  left: 0;

Â  right: 0;

Â  bottom: 0;

Â  display: flex;

Â  align-items: center;

Â  justify-content: center;

Â  background-color: rgba(0, 0, 0, 0.2);

Â  pointer-events: none;

Â  z-index: 5;

Â  padding: 0.75rem;

Â  box-sizing: border-box;

Â  opacity: 1;

Â  transition: opacity 0.2s ease-in-out;

}

.loading-indicator-visual {

Â  width: 24px;

Â  height: 24px;

Â  border-radius: 50%;

Â  background: radial-gradient(

Â  Â  circle,

Â  Â  color-mix(in srgb, var(--accent-color-primary) 80%, white) 0%,

Â  Â  var(--accent-color-primary) 50%,

Â  Â  color-mix(in srgb, var(--accent-color-primary) 50%, transparent) 70%

Â  );

Â  animation: plasma-pulse 1.2s infinite ease-in-out;

Â  box-shadow: 0 0 8px 2px color-mix(in srgb, var(--accent-color-primary) 50%, transparent);

Â  position: relative;

Â  overflow: visible;

}

@keyframes plasma-pulse {

Â  0% {

Â  Â  transform: scale(0.8);

Â  Â  opacity: 0.7;

Â  Â  box-shadow: 0 0 6px 1px color-mix(in srgb, var(--accent-color-primary) 40%, transparent);

Â  }

Â  50% {

Â  Â  transform: scale(1);

Â  Â  opacity: 1;

Â  Â  box-shadow: 0 0 12px 3px color-mix(in srgb, var(--accent-color-primary) 60%, transparent);

Â  }

Â  100% {

Â  Â  transform: scale(0.8);

Â  Â  opacity: 0.7;

Â  Â  box-shadow: 0 0 6px 1px color-mix(in srgb, var(--accent-color-primary) 40%, transparent);

Â  }

}

.loading-indicator-visual::before,

.loading-indicator-visual::after {

Â  content: '';

Â  position: absolute;

Â  top: 50%;

Â  left: 50%;

Â  width: 2px;

Â  height: 10px;

Â  background-color: var(--accent-color-primary);

Â  border-radius: 1px;

Â  transform-origin: 50% 50%;

Â  animation: plasma-shoot 0.6s infinite linear;

Â  opacity: 0;

Â  box-shadow: 0 0 3px 1px color-mix(in srgb, var(--accent-color-primary) 80%, transparent);

}

.loading-indicator-visual::before {

Â  transform: translate(-50%, -50%) rotate(0deg);

Â  --angle: 0deg;

}

.loading-indicator-visual::after {

Â  transform: translate(-50%, -50%) rotate(90deg);

Â  animation-delay: -0.3s;

Â  --angle: 90deg;

}

@keyframes plasma-shoot {

Â  0% {

Â  Â  transform: translate(-50%, -50%) scale(0.8) rotate(var(--angle, 0deg));

Â  Â  opacity: 0.9;

Â  Â  height: 8px;

Â  }

Â  70% {

Â  Â  opacity: 0.3;

Â  Â  height: 20px;

Â  Â  transform: translate(-50%, -50%) scale(2.5) rotate(var(--angle, 0deg));

Â  }

Â  100% {

Â  Â  transform: translate(-50%, -50%) scale(3.5) rotate(var(--angle, 0deg));

Â  Â  opacity: 0;

Â  Â  height: 3px;

Â  }

}

</style>
